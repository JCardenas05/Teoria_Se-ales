{"cells":[{"cell_type":"code","metadata":{"cell_id":"373c4164b432407d9bb1a380e1750d9a","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an SVM model\nmodel = SVC()\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"0b07efe7ffcd43188c6c394ccf14f9c4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"7fdbb1fc23254c4c8a246bd1425f947f","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an XGBoost model\nmodel = XGBClassifier()\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"3012af88759e45c3a5130bf55ed002d1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"ad38cd73f1ae4f4c88f932a651685b83","deepnote_cell_type":"code"},"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming 'X' is your feature matrix and 'y' is your target variable\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a logistic regression model\nmodel = LogisticRegression()\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"ad38cd73f1ae4f4c88f932a651685b83","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"4af123e14d904319a025665c6867ef58","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming 'X' is your feature matrix and 'y' is your target variable\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Build a simple neural network\nmodel = Sequential()\nmodel.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate accuracy\n_, accuracy = model.evaluate(X_test, y_test)\nprint(f'Accuracy: {accuracy}')\n\n# Make predictions\ny_pred = model.predict_classes(X_test)\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"8dbc1068a50245ac9a81c35a18097d84","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"d021c190994543d095cfbf1a4b7c73cd","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a Neural Network model\nmodel = Sequential()\nmodel.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')\n","block_group":"5155a9f802e9460b9fc88ed0ae842711","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"cb784bde462e4ce198b627714b16d177","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Reshape X for RNN input (assuming 3D input with samples, time steps, and features)\n# You can adjust 'n_steps' based on your sequence length\nn_steps = 3\nX = np.array([X[i:i + n_steps] for i in range(len(X) - n_steps)])\ny = y[n_steps - 1:]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an RNN model\nmodel = Sequential()\nmodel.add(SimpleRNN(50, activation='relu', input_shape=(n_steps, X.shape[2])))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"37a98a2e3f1d4f1ca20d3550e14e41d4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"d657b6eeffa842f5ade7f384a91cc84e","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GRU, Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Reshape X for GRU input (assuming 3D input with samples, time steps, and features)\nn_steps = 3  # You can adjust this based on your sequence length\nX = np.array([X[i:i + n_steps] for i in range(len(X) - n_steps)])\ny = y[n_steps - 1:]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a GRU model\nmodel = Sequential()\nmodel.add(GRU(50, activation='relu', input_shape=(n_steps, X.shape[2])))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"aed76c5e343b44b7bcc50824683cb1e1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"d854043655b245f698c6b99b0a331d8c","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Reshape X for LSTM input (assuming 3D input with samples, time steps, and features)\nX = X.reshape((X.shape[0], 1, X.shape[1]))\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an LSTM model\nmodel = Sequential()\nmodel.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"17dad405ed434ebeafb299818f4eb873","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"bc0700b050304b8ca511dff3b61c8d20","deepnote_cell_type":"markdown"},"source":"rnn + lstm","block_group":"2961671fea404a3899a7c93ec20286a1"},{"cell_type":"code","metadata":{"cell_id":"f294764d77e94b33b73e954ece81b672","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Reshape X for LSTM input (assuming 3D input with samples, time steps, and features)\nn_steps = 3  # You can adjust this based on your sequence length\nX = np.array([X[i:i + n_steps] for i in range(len(X) - n_steps)])\ny = y[n_steps - 1:]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an LSTM model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', input_shape=(n_steps, X.shape[2])))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"65e44338e6444f9b880174c0baf9bbbb","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"7ea55541316a429087d128e2c58e211b","deepnote_cell_type":"markdown"},"source":"autoencoder for anomaly detection","block_group":"db3f3d10fa814cd3a3aed868c4455f03"},{"cell_type":"code","metadata":{"cell_id":"74f614b937bd48b18dd99509f7e88f6d","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an autoencoder model for anomaly detection\nmodel = Sequential([\n    Dense(32, activation='relu', input_shape=(X.shape[1],)),\n    Dense(16, activation='relu'),\n    Dense(8, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(X.shape[1], activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the autoencoder on normal samples (class 0)\nmodel.fit(X_train[y_train == 0], X_train[y_train == 0], epochs=10, batch_size=32, validation_data=(X_test, X_test))\n\n# Use the trained autoencoder for reconstruction on the test set\nreconstructed_X = model.predict(X_test)\n\n# Calculate Mean Squared Error (MSE) between original and reconstructed samples\nmse = np.mean(np.power(X_test - reconstructed_X, 2), axis=1)\n\n# Set a threshold for anomaly detection\nthreshold = np.mean(mse) + 2 * np.std(mse)\n\n# Classify samples based on the threshold\ny_pred = np.where(mse > threshold, 1, 0)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"d67b09732f35495c8c48847daadcfde1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"661acad061dc4324b0af75ec449111fe","deepnote_cell_type":"markdown"},"source":"To perform binary classification using an autoencoder in Python, you can approach it as an unsupervised pretraining step, followed by a supervised fine-tuning step. Here’s a basic example using TensorFlow and Keras:","block_group":"66d28d386b0b4f5999ea41cdb2fce17f"},{"cell_type":"code","metadata":{"cell_id":"aa5fd33e0ff84d058d3714ed39537687","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an autoencoder model\nautoencoder = Sequential([\n    Dense(32, activation='relu', input_shape=(X.shape[1],)),\n    Dense(16, activation='relu'),\n    Dense(8, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(X.shape[1], activation='sigmoid')\n])\n\n# Compile the autoencoder model\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the autoencoder\nautoencoder.fit(X_train, X_train, epochs=10, batch_size=32, validation_data=(X_test, X_test))\n\n# Extract encoder part for feature extraction\nencoder = Sequential(autoencoder.layers[:3])  # Adjust based on the number of layers you want to use for encoding\n\n# Freeze the layers in the encoder during fine-tuning\nfor layer in encoder.layers:\n    layer.trainable = False\n\n# Create a binary classification model by adding a dense layer on top of the encoder\nbinary_model = Sequential([\n    encoder,\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the binary classification model\nbinary_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Fine-tune the model on the binary classification task\nbinary_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = binary_model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"1fe068c7aed04f24876ffce9d6b04e30","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"2c8e7e2752d24ae095bc50411094b84c","deepnote_cell_type":"markdown"},"source":"binary classification using an autoencoder with a dedicated classifier on top, you can follow a semi-supervised approach. Here’s an example using TensorFlow and Keras:","block_group":"2a508dfe6371451a8bd035cc2c2b818b"},{"cell_type":"code","metadata":{"cell_id":"96afa1368c304b4a81aea6fa64b52203","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Assuming you have a DataFrame 'df' with features and target variable\n# Example: df = pd.read_csv('your_dataset.csv')\n\n# Separate features (X) and target variable (y)\nX = df.drop('target_variable', axis=1)\ny = df['target_variable']\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create an autoencoder model\nautoencoder = Sequential([\n    Dense(32, activation='relu', input_shape=(X.shape[1],)),\n    Dense(16, activation='relu'),\n    Dense(8, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(X.shape[1], activation='sigmoid')\n])\n\n# Compile the autoencoder model\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the autoencoder\nautoencoder.fit(X_train, X_train, epochs=10, batch_size=32, validation_data=(X_test, X_test))\n\n# Extract encoder part for feature extraction\nencoder = Sequential(autoencoder.layers[:3])  # Adjust based on the number of layers you want to use for encoding\n\n# Freeze the layers in the encoder during fine-tuning\nfor layer in encoder.layers:\n    layer.trainable = False\n\n# Create a binary classification model by adding a dense layer on top of the encoder\nbinary_model = Sequential([\n    encoder,\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the binary classification model\nbinary_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Fine-tune the model on the binary classification task\nbinary_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Make predictions\ny_pred_probs = binary_model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix:\\n{conf_matrix}')","block_group":"6adaf2541fca43febde6b83745bdd02d","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=979fc9bf-f8fd-410e-a8ea-123981ebd7a4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"659f5c1e89ea43e3bbe9a9d68137fbc9","deepnote_execution_queue":[]}}